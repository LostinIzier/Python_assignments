{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c753c4",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:blue\">Codebasics Python Course: Exercise - Comprehensions, Sets</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbb5a6-f24e-4f67-9d8d-2ee65a7bdadc",
   "metadata": {},
   "source": [
    "**Loki** shared a few ad-hoc tasks that his team is working on across different projects at **AtliQ**, and now you will be helping him with them.\n",
    "\n",
    "<img src=\"https://files.codebasics.io/55188/avatar/lokhi.png\" width=\"10%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe45535-374e-4d8c-8427-ac690ac0c178",
   "metadata": {},
   "source": [
    "### Task 1: Inventory Analysis for E-Commerce Client\n",
    "\n",
    "**AtliQ**, a service-based software company, is supporting an e-commerce client in analyzing their inventory data. The client wants to gain insights into the range of product categories available in their inventory. Your task, as part of the AtliQ team, is to identify and print all the unique product categories from a list of product records provided.\n",
    "\n",
    "You will be given a dataset containing product details, and your goal is to extract and display the distinct product categories present in the inventory.\n",
    "\n",
    "**Expected Output**\n",
    "\n",
    "\n",
    "Unique Product Categories:\n",
    "\n",
    "- Electronics\n",
    "- Apparel\n",
    "- Home Appliances\n",
    "- Literatureure\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f1d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"product_name\": \"Laptop\", \"category\": \"Electronics\", \"price\": 1200},\n",
    "    {\"product_name\": \"Jeans\", \"category\": \"Apparel\", \"price\": 40},\n",
    "    {\"product_name\": \"Coffee Maker\", \"category\": \"Home Appliances\", \"price\": 80},\n",
    "    {\"product_name\": \"Smartphone\", \"category\": \"Electronics\", \"price\": 999},\n",
    "    {\"product_name\": \"Jacket\", \"category\": \"Apparel\", \"price\": 60},\n",
    "    {\"product_name\": \"Blender\", \"category\": \"Home Appliances\", \"price\": 150},\n",
    "    {\"product_name\": \"Book\", \"category\": \"Literature\", \"price\": 15}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb1f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronics' 'Apparel' 'Home Appliances' 'Literature']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.DataFrame(products).category.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845798d2-81c1-47c9-a6ee-780e0407f2c2",
   "metadata": {},
   "source": [
    "### Task 2: Audience Analysis for Music Festival Organizer\n",
    "\n",
    "As the other team got occupied with an urgent task, you have been asked to assist another client on an ad-hoc basis. The client is a music festival organizer looking to optimize event planning and marketing strategies by understanding audience overlap between concerts. \n",
    "\n",
    "Your task is to help analyze the data and:\n",
    "\n",
    "1. Identify unique attendees for each concert.\n",
    "2. Find common attendees across the concerts.\n",
    "\n",
    "The attendee data is provided in the next cell. Use set operations to complete the analysis and print a summary of the results.\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "Unique Attendees for Each Concert:\r\n",
    "- Concert A Only: {'Charlie'}\r\n",
    "- Concert B Only: {'Eve'}\r\n",
    "- Concert C Only: {'George', 'Elle'}\r\n",
    "\r\n",
    "Common Attendees Between All Concerts: {'Bob'}\r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fc6ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concert_a_attendees = {\"Alice\", \"Bob\", \"Charlie\", \"Diana\"}\n",
    "concert_b_attendees = {\"Bob\", \"Diana\", \"Eve\", \"Frank\"}\n",
    "concert_c_attendees = {\"Alice\", \"George\", \"Elle\", \"Frank\",\"Bob\"}\n",
    "a=concert_a_attendees\n",
    "b=concert_b_attendees\n",
    "c=concert_c_attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13426f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concert A Only: [{'Charlie'}]\n",
      "Concert b Only: [{'Eve'}]\n",
      "Concert cOnly: [{'Elle', 'George'}]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Concert A Only: {[a-(a&b)-(a&c)]}\")\n",
    "print(f\"Concert b Only: {[b-(b&a)-(b&c)]}\")\n",
    "print(f\"Concert cOnly: {[c-(c&b)-(c&a)]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fdaa64",
   "metadata": {},
   "source": [
    "### Task 3: Temperature Trend Analysis\n",
    "\n",
    "In this task, you've been assigned to help a client who is analyzing daily temperature records for a month to understand temperature trends. The client is particularly interested in identifying the records when the temperature exceeded **70Â°F.**\n",
    "\n",
    "Your responsibility is to analyze this dataset and extract the records where the maximum temperature was above 70Â°F. \n",
    "\n",
    "Display the filtered temperatures.\n",
    "\n",
    "The temperature data is given in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c229a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_temperatures = [68, 71, 74, 69, 70, 71, 68, 73, 72, 71, 70, 74, 72, 68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dc59a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "74\n",
      "71\n",
      "73\n",
      "72\n",
      "71\n",
      "74\n",
      "72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(x)for x in daily_temperatures if x>70 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbcb92",
   "metadata": {},
   "source": [
    "### Task 4: Identifying Unique Temperatures\n",
    "\n",
    "The client wants to find all unique temperature values recorded over a month. Your task is to use set comprehension to extract and print the unique temperatures from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bef5837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{68, 69, 70, 71, 72, 73, 74}\n"
     ]
    }
   ],
   "source": [
    "s=set(daily_temperatures)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107f9b4",
   "metadata": {},
   "source": [
    "### Task 5: Temperature Frequency Analysis\n",
    "\n",
    "Identify how often each temperature was recorded over a month. Your task is to use dictionary comprehension to count and print the occurrences of each temperature in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02f5d27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{68: 3, 71: 3, 74: 2, 69: 1, 70: 2, 73: 1, 72: 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x:daily_temperatures.count(x)for x in daily_temperatures}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66b697",
   "metadata": {},
   "source": [
    "### Task 6: Social Media Engagement Analysis\n",
    "\n",
    "You are tasked with helping a client analyze their social media data to identify trending hashtags and measure user engagement. Specifically, you need to extract posts that have received more than 100 likes. Your task is to filter these posts and store them in a variable called popular_posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e4eef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [\n",
    "    {\"content\": \"Loving the sunny weather today! #sunny #happy\", \"likes\": 120},\n",
    "    {\"content\": \"Nothing beats a beach day. #beachday #sunny\", \"likes\": 350},\n",
    "    {\"content\": \"A rainy day at home. #rainy #lazyday\", \"likes\": 75},\n",
    "    {\"content\": \"Best coffee in town. #coffeelove #morning\", \"likes\": 180},\n",
    "    {\"content\": \"Can't wait for the weekend. #weekend #party\", \"likes\": 90}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e131288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Loving the sunny weather today! #sunny #happy', 'likes': 120},\n",
       " {'content': 'Nothing beats a beach day. #beachday #sunny', 'likes': 350},\n",
       " {'content': 'Best coffee in town. #coffeelove #morning', 'likes': 180}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_posts=[]\n",
    "[popular_posts.append(x)for x in posts if x[\"likes\"]>100]\n",
    "popular_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04d6c8",
   "metadata": {},
   "source": [
    "### Task 7: Unique Hashtag Extraction\n",
    "Building on the previous task, now that you've identified the popular posts, the client wants to understand which hashtags are being used across these posts. Your task is to extract all unique hashtags from the popular posts.\n",
    "\n",
    "The list of popular posts is provided from the previous task.\n",
    "\n",
    "Tip ðŸ’¡: Use set comprehension to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5965d905-e34b-413a-b635-88b1ba310a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting regex\n",
      "  Downloading regex-2026.1.15-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Downloading regex-2026.1.15-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2026.1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de31c56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#sunny', '#happy', '#beachday', '#sunny', '#coffeelove', '#morning']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "l=[]\n",
    "hashtags=set()\n",
    "{hashtags.update(re.findall(r'#\\w+',x['content']))for x in popular_posts}\n",
    "[l.extend(re.findall(r'#\\w+',x['content']))for x in popular_posts]\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca72892",
   "metadata": {},
   "source": [
    "### Task 8: Hashtag Frequency Analysis\n",
    "\n",
    "In this task, the client wants to understand how frequently each hashtag appears in the popular posts. Your task is to count the occurrences of each hashtag from the popular posts using dictionary comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4f76700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#coffeelove': 1, '#beachday': 1, '#morning': 1, '#sunny': 2, '#happy': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x:l.count(x)for x in hashtags}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
